{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'datasets/')\n",
    "sys.path.insert(0, 'models/research/audioset/vggish/')\n",
    "import dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import vggish as vggish_import\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microphone Locations\n",
    "mic_height = 50.3125\n",
    "feet = 12\n",
    "y_tile = 23.5\n",
    "x_tile = 11 +7/8\n",
    "\n",
    "camera_origin_location = np.array([-6*x_tile-5.75, -y_tile, 45+13/16])*25.4\n",
    "\n",
    "mic_1 = np.array([-11*x_tile - 1, -5*y_tile - 6-3/8, mic_height]) * 25.4 \n",
    "mic_4= np.array([-11*x_tile + 1.25 + 1/16, 2.5*y_tile+3.75, mic_height]) * 25.4\n",
    "mic_6 = np.array([5+3/8, 2+1/8, mic_height]) * 25.4\n",
    "mic_9 = np.array([-3, -6*y_tile - 0.5, mic_height]) * 25.4\n",
    "\n",
    "\n",
    "mic_xyzs = np.stack((mic_1,mic_4, mic_6, mic_9),axis=0)\n",
    "\n",
    "SPEAKER_BOTTOM_RIGHT_Y = (1200.15 + 1196.975 + 1206.5)/ 3\n",
    "SPEAKER_BOTTOM_RIGHT_X = (88.9 + 107.95 + 101.6) / 3\n",
    "SPEAKER_BOTTOM_LEFT_Y = (1327.15 + 1311.55712764 + 1317.625) / 3\n",
    "SPEAKER_BOTTOM_LEFT_X = - 76.98583188\n",
    "\n",
    "speaker_xyz_bottom_right = np.array([SPEAKER_BOTTOM_RIGHT_X, SPEAKER_BOTTOM_RIGHT_Y, 44.5*25.4])\n",
    "speaker_xyz_bottom_left = np.array([SPEAKER_BOTTOM_LEFT_X, SPEAKER_BOTTOM_LEFT_Y, 44.5*25.4])\n",
    "speaker_xyz_top_right = np.array([SPEAKER_BOTTOM_RIGHT_X, SPEAKER_BOTTOM_RIGHT_Y, (44.5+17)*25.4])\n",
    "speaker_xyz_top_left = np.array([SPEAKER_BOTTOM_LEFT_X, SPEAKER_BOTTOM_LEFT_Y, (44.5+17)*25.4])\n",
    "speaker_xyz = (speaker_xyz_bottom_right+speaker_xyz_bottom_left+speaker_xyz_top_right+speaker_xyz_top_left)/4\n",
    "\n",
    "\n",
    "walls = None\n",
    "x_min = - 4000\n",
    "x_max = 500\n",
    "y_min = -4000\n",
    "y_max = 2000\n",
    "\n",
    "mic_xyzs_base = np.stack((mic_1, mic_4, mic_6, mic_9), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Living Room Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "import room_config\n",
    "DATASET_BASE_PATH = \"/home/onyxia/work/ia_data_hack_acoustic/data/LivingRoom_preprocessed_hack\"\n",
    "\n",
    "DATASET_PATH = (f\"{DATASET_BASE_PATH}/Human1\")\n",
    "\n",
    "#Load dataset attributes - the treated room is called \"darkroom\" ->> replace by the right values\n",
    "dr = room_config.Dataset(room_config.RoomSetup(speaker_xyz,\n",
    "                mic_xyzs_base,\n",
    "                x_min,\n",
    "                x_max,\n",
    "                y_min,\n",
    "                y_max,\n",
    "                walls), DATASET_PATH)\n",
    "\n",
    "\n",
    "print(\"Living Room Dataset Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humains : (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "centroid = np.load(f\"{DATASET_PATH}/centroid.npy\")\n",
    "print(f\"humains : {centroid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rirs : (1000, 4, 667200)\n"
     ]
    }
   ],
   "source": [
    "deconv = np.load(f\"{DATASET_PATH}/deconvoled_trim.npy\", mmap_mode='r')\n",
    "print(f\"rirs : {deconv.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training xys\n",
      "(800, 2)\n"
     ]
    }
   ],
   "source": [
    "train_indices = np.load(\"indices/train_indices.npy\")\n",
    "train_xys = centroid[train_indices]\n",
    "\n",
    "print(\"Shape of Training xys\")\n",
    "print(train_xys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rand = random.Random(10)\n",
    "    \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4, 667200)\n"
     ]
    }
   ],
   "source": [
    "mic_indices = [0,1,2,3] #[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]#[1, 4, 6, 9] #[8, 0, 5, 3] #mic_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "deconv = deconv[:, mic_indices, :]\n",
    "print(deconv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.load(\"indices/train_indices.npy\")\n",
    "valid_indices = np.load(\"indices/valid_indices.npy\")\n",
    "test_indices = np.load(\"indices/test_indices.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1065.49002101 1413.40889991]\n",
      "[  56.83489407 1542.25968982]\n",
      "[-4002.15528594 -3499.88767611]\n"
     ]
    }
   ],
   "source": [
    "train_xy = centroid[train_indices]\n",
    "valid_xy = centroid[valid_indices]\n",
    "test_xy = centroid[test_indices]\n",
    "\n",
    "train_mean = np.mean(train_xy, axis=0)\n",
    "train_std = np.std(train_xy, axis=0)\n",
    "\n",
    "print(train_std)\n",
    "print(np.max(train_xy, axis=0))\n",
    "print(np.min(train_xy, axis=0))\n",
    "train_xy = (train_xy - train_mean) / (train_std + 1e-8)\n",
    "valid_xy = (valid_xy - train_mean) / (train_std + 1e-8)\n",
    "test_xy =  (test_xy - train_mean) / (train_std + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-2\n",
    "norm_val_min = np.min(np.concatenate((train_xy, valid_xy), axis=0))\n",
    "norm_val_range = np.max(np.concatenate((train_xy, valid_xy), axis=0)) - norm_val_min\n",
    "\n",
    "def postprocess_net_output(output):\n",
    "    output[:, :2] = norm_val_range * ((torch.tanh(output[:, :2]) * (1 + epsilon)) + 1) / 2 + norm_val_min\n",
    "    return output\n",
    "\n",
    "\n",
    "train_std_cuda = torch.Tensor(train_std)\n",
    "train_mean_cuda = torch.Tensor(train_mean)\n",
    "\n",
    "def unnormalize(xy):\n",
    "    return xy*(train_std_cuda + 1e-8) + train_mean_cuda\n",
    "\n",
    "def resample(audio, ir=48000, tr=16000):\n",
    "\n",
    "    resampled_waveform = F.resample(\n",
    "    audio,\n",
    "    ir,\n",
    "    tr,\n",
    "    lowpass_filter_width=64,\n",
    "    rolloff=0.9475937167399596,\n",
    "    resampling_method=\"kaiser_window\",\n",
    "    beta=14.769656459379492,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_waves = deconv[train_indices, :]\n",
    "# 30950 seems to be the rough cutoff after which vggish treats the input as two examples.\n",
    "valid_waves = deconv[valid_indices, :]\n",
    "#Test Waves\n",
    "test_waves = deconv[test_indices, :]\n",
    "offset = 0\n",
    "precutoff = 92850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_waves = train_waves[..., (offset):(offset+precutoff)]\n",
    "valid_waves = valid_waves[..., (offset):(offset+precutoff)]\n",
    "test_waves = test_waves[..., (offset):(offset+precutoff)]\n",
    "\n",
    "train_waves = torch.Tensor(train_waves)\n",
    "train_xy = torch.Tensor(train_xy)\n",
    "\n",
    "valid_waves = torch.Tensor(valid_waves)\n",
    "valid_xy = torch.Tensor(valid_xy)\n",
    "\n",
    "test_waves = torch.Tensor(test_waves)\n",
    "test_xy = torch.Tensor(test_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Resampling\n"
     ]
    }
   ],
   "source": [
    "vggish_cutoff = 30950\n",
    "\n",
    "train_waves = train_waves[..., :vggish_cutoff]\n",
    "valid_waves = valid_waves[..., :vggish_cutoff]\n",
    "test_waves = test_waves[..., :vggish_cutoff]\n",
    "\n",
    "out_channels = 2\n",
    "\n",
    "print(\"Done Resampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggish_model_urls = {\n",
    "    'vggish': 'https://github.com/harritaylor/torchvggish/'\n",
    "              'releases/download/v0.1/vggish-10086976.pth',\n",
    "    'pca': 'https://github.com/harritaylor/torchvggish/'\n",
    "           'releases/download/v0.1/vggish_pca_params-970ea276.pth'\n",
    "}\n",
    "\n",
    "def vggish_test(pretrained=True, **kwargs):\n",
    "    model = vggish_import.VGGish(urls=vggish_model_urls, pretrained_net=pretrained, postprocess=pretrained, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGModel(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self, fs=16000, pretrained=True):\n",
    "        super(VGGModel, self).__init__()\n",
    "        # self.vggish = torch.hub.load('harritaylor/torchvggish', 'vggish')\n",
    "        self.vggish = vggish_test(pretrained=pretrained)\n",
    "        self.vggish.eval()\n",
    "        self.fs = fs\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = (self.vggish.forward(torch.unsqueeze(x, axis=1), fs=self.fs) / 127) - 1\n",
    "        # x = (self.vggish.forward(np.expand_dims(x, axis=1), fs=self.fs) / 127) - 1\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finetune_model(pretrained=True, frozen=True, out_channels=2, dropout=False, in_channels=1):\n",
    "    # TODO(sclarke): This pretrained model is based on 16kHz samples, and automatically downsamples input audio to 16k\n",
    "    vggish_model = VGGModel(fs=room_config.PSEUDO_SAMPLE_RATE, pretrained=pretrained)\n",
    "    if pretrained and frozen:\n",
    "        for param in vggish_model.parameters():\n",
    "            param.requires_grad = False\n",
    "    p_dropout = 0.5 if dropout else 0.0\n",
    "    finetune_model = torch.nn.Sequential(\n",
    "        vggish_model,\n",
    "        torch.nn.Linear(in_features=128, out_features=256, bias=True),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(p_dropout),\n",
    "        torch.nn.Linear(in_features=256, out_features=256, bias=True),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(p_dropout),\n",
    "        # torch.nn.Linear(in_features=256, out_features=256, bias=True),\n",
    "        # torch.nn.ReLU(),\n",
    "        torch.nn.Linear(in_features=256, out_features=out_channels, bias=True)\n",
    "    )\n",
    "    \n",
    "    return finetune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using VGGish-based model\n"
     ]
    }
   ],
   "source": [
    "train_waves = torch.mean(train_waves)\n",
    "valid_waves = torch.mean(valid_waves)\n",
    "test_waves = torch.mean(test_waves)\n",
    "\n",
    "net = get_finetune_model(pretrained=False, frozen=False, out_channels=out_channels)\n",
    "#test = VGGModel(fs=room_config.PSEUDO_SAMPLE_RATE, pretrained=True)\n",
    "print('Using VGGish-based model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "\n",
    "print('Total parameters: %i'%total_params)\n",
    "print('Trainable parameters: %i'%trainable_params)\n",
    "\n",
    "xy_loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(params=net.parameters(), betas=(0.9, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.999995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_iter = 10\n",
    "train_losses = []\n",
    "train_xy_losses = []\n",
    "valid_losses = []\n",
    "valid_xy_losses = []\n",
    "step_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(args.num_epochs):\n",
    "    print('Reshuffling for Epoch %i'%n, flush=True)\n",
    "    rand_idx = np.random.permutation(train_waves.shape[0])\n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(N_iter):\n",
    "        curr_idx = rand_idx[i*args.batch_size:(i+1)*args.batch_size]\n",
    "        net_out = net(train_waves[curr_idx, :])\n",
    "        results = postprocess_net_output(net_out)\n",
    "        xy_loss = xy_loss_fn(results[:, :2], train_xy[curr_idx, :2])\n",
    "        loss = xy_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_loss = loss.item()\n",
    "        train_losses.append((step_count, train_loss))\n",
    "        train_xy_losses.append((step_count, xy_loss.item()))\n",
    "        step_count+=1\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    net.eval()\n",
    "    valid_loss_xy_arr = np.zeros(valid_waves.shape[0], dtype=np.float32)\n",
    "    valid_loss_arr = np.zeros(valid_waves.shape[0], dtype=np.float32)\n",
    "    for i in range(valid_waves.shape[0]):\n",
    "        with torch.no_grad():\n",
    "            results = torch.squeeze(postprocess_net_output(net(torch.unsqueeze(valid_waves[i, :], axis=0)).view(-1, 1)))\n",
    "        xy_loss = xy_loss_fn(results[:2], valid_xy[i, :2])\n",
    "        valid_loss_xy_arr[i] = xy_loss.item()\n",
    "        loss = xy_loss\n",
    "        valid_loss_arr[i] = loss.item()\n",
    "    valid_xy_loss = np.mean(valid_loss_xy_arr)\n",
    "    valid_loss = np.mean(valid_loss_arr)\n",
    "    print('Validation XY Loss: %0.3f'%valid_xy_loss)\n",
    "    print('Validation Loss: %0.3f'%valid_loss)\n",
    "    valid_losses.append((step_count, valid_loss))\n",
    "    valid_xy_losses.append((step_count, valid_xy_loss))\n",
    "\n",
    "\n",
    "    error_path = \"../err\"\n",
    "    if not os.path.exists(error_path):\n",
    "        os.makedirs(args.error_path)\n",
    "\n",
    "    np.save(os.path.join(error_path, 'train_losses.npy'), np.array(train_losses, dtype=np.float32))\n",
    "    np.save(os.path.join(error_path, 'valid_losses.npy'), np.array(valid_losses, dtype=np.float32))\n",
    "\n",
    "    #Iterate through test\n",
    "    test_errors = np.zeros(test_waves.shape[0], dtype=np.float32)\n",
    "\n",
    "    for i in range(test_waves.shape[0]):\n",
    "        with torch.no_grad():\n",
    "            results = torch.squeeze(postprocess_net_output(net(torch.unsqueeze(test_waves[i, :], axis=0)).view(-1, 1)))\n",
    "        \n",
    "        \n",
    "        test_errors[i] = torch.norm(unnormalize(results[:2]) - unnormalize(test_xy[i, :2])).item()\n",
    "\n",
    "    print(\"TEST ERROR\")\n",
    "    print(test_errors)\n",
    "    \n",
    "    print(\"MEAN TEST ERROR\",flush=True)\n",
    "    print(np.mean(test_errors))\n",
    "    print(\"MED TEST ERROR\")\n",
    "    print(np.median(test_errors))\n",
    "    print(\"STD TEST ERROR\")\n",
    "    print(np.std(test_errors))\n",
    "\n",
    "    np.save(os.path.join(args.error_path, 'test_errors.npy'), np.array(test_errors, dtype=np.float32))        \n",
    "\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': n,\n",
    "        'model_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'train_xy_losses': train_xy_losses,\n",
    "        'valid_losses': valid_losses,\n",
    "        'valid_xy_losses': valid_xy_losses,\n",
    "        'train_mean': train_mean,\n",
    "        'train_std': train_std,\n",
    "        'norm_val_min':norm_val_min,\n",
    "        'norm_val_range':norm_val_range,\n",
    "        'lr': args.lr,\n",
    "        }, args.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
