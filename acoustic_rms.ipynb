{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutoriel : interagir avec le système de stockage S3 du SSP Cloud (MinIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import s3fs\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérer les données d'un challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filesystem object\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Télécharger les données dans le service\n",
    "PATH_IN = 'samicarret/diffusion/TreatedRoomSmallSet2.zip'\n",
    "fs.download(PATH_IN, 'data/HC3.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Décompresser les données\n",
    "with zipfile.ZipFile(\"data/HC3.zip\",\"r\") as zip_file:\n",
    "    zip_file.extractall(\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = np.load('data/TreatedRoomSmallSet/Human1/centroid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2425.77063278,  -657.46941402],\n",
       "       [ 1744.17081831,  -944.2440339 ],\n",
       "       [ 2320.19919293, -2464.72205234]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = np.load('data/TreatedRoomSmallSet/Human1/audio.npy')\n",
    "adjusted_audio = np.load('data/TreatedRoomSmallSet/Human1/adjusted_audio.npy')\n",
    "\n",
    "deconvolved = np.load('data/TreatedRoomSmallSet/Human1/deconvolved.npy')\n",
    "directlines = np.load('data/TreatedRoomSmallSet/Human1/directlines.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape des niveaux RMS: (3, 10)\n",
      "Niveaux RMS pour le premier enregistrement:\n",
      "[29.70875137 29.20671747 25.63379974 23.46920801 24.2696896  27.74678054\n",
      " 20.81851468 25.1604534  24.41105036 31.64709987]\n"
     ]
    }
   ],
   "source": [
    "rms_audio = np.sqrt(np.mean(np.square(audio), axis=2))  # Calculer RMS sur l'axe des échantillons\n",
    "\n",
    "# Vérifier la forme des niveaux RMS\n",
    "print(\"Shape des niveaux RMS:\", rms_audio.shape)  # [N_datapoints, N_Microphones]\n",
    "\n",
    "# Exemple : Niveaux RMS pour le premier enregistrement\n",
    "print(\"Niveaux RMS pour le premier enregistrement:\")\n",
    "print(rms_audio[0])  # Afficher les niveaux RMS du premier enregistrement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape du tableau combiné: (3, 12)\n",
      "Premières lignes du tableau combiné:\n",
      "[[   29.70875137    29.20671747    25.63379974    23.46920801\n",
      "     24.2696896     27.74678054    20.81851468    25.1604534\n",
      "     24.41105036    31.64709987  2425.77063278  -657.46941402]\n",
      " [   31.34640352    29.93810895    30.00472626    24.26575375\n",
      "     31.04475679    29.63319339    22.08850504    27.39462351\n",
      "     26.56226851    38.20548557  1744.17081831  -944.2440339 ]\n",
      " [   34.85986726    29.18252056    25.56728984    24.03735916\n",
      "     23.73848728    27.03857834    22.23435472    25.80769672\n",
      "     23.98810621    32.3542175   2320.19919293 -2464.72205234]]\n"
     ]
    }
   ],
   "source": [
    "# Concaténer les niveaux RMS avec les positions de centroid\n",
    "data_with_positions = np.concatenate((rms_audio, file), axis=1)\n",
    "\n",
    "# Vérifier la forme du tableau combiné\n",
    "print(\"Shape du tableau combiné:\", data_with_positions.shape)  # [N_datapoints, N_Microphones + 2]\n",
    "\n",
    "# Vérifier les premières lignes du tableau\n",
    "print(\"Premières lignes du tableau combiné:\")\n",
    "print(data_with_positions[:5])  # Afficher les premières lignes pour vérification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape du tableau combiné: (3, 12)\n",
      "Premières lignes du tableau combiné:\n",
      "[[   29.70875137    29.20671747    25.63379974    23.46920801\n",
      "     24.2696896     27.74678054    20.81851468    25.1604534\n",
      "     24.41105036    31.64709987  2425.77063278  -657.46941402]\n",
      " [   31.34640352    29.93810895    30.00472626    24.26575375\n",
      "     31.04475679    29.63319339    22.08850504    27.39462351\n",
      "     26.56226851    38.20548557  1744.17081831  -944.2440339 ]\n",
      " [   34.85986726    29.18252056    25.56728984    24.03735916\n",
      "     23.73848728    27.03857834    22.23435472    25.80769672\n",
      "     23.98810621    32.3542175   2320.19919293 -2464.72205234]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger les données nécessaires (audio.npy et centroid.npy)\n",
    "audio = np.load('data/TreatedRoomSmallSet/Human1/audio.npy')\n",
    "centroid = np.load('data/TreatedRoomSmallSet/Human1/centroid.npy')\n",
    "\n",
    "# Calculer les niveaux RMS pour chaque enregistrement pour les 4 micros\n",
    "rms_audio = np.sqrt(np.mean(np.square(audio), axis=2))\n",
    "\n",
    "# Concaténer les niveaux RMS avec les positions de centroid\n",
    "data_with_positions = np.concatenate((rms_audio, centroid), axis=1)\n",
    "\n",
    "# Vérifier la forme du tableau combiné\n",
    "print(\"Shape du tableau combiné:\", data_with_positions.shape)  # [N_datapoints, N_Microphones + 2]\n",
    "\n",
    "# Vérifier les premières lignes du tableau\n",
    "print(\"Premières lignes du tableau combiné:\")\n",
    "print(data_with_positions[:5])  # Afficher les premières lignes pour vérification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Créer le dossier data s'il n'existe pas\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Charger les données nécessaires (audio.npy et centroid.npy)\n",
    "audio = np.load('data/TreatedRoomSmallSet/Human1/audio.npy')\n",
    "centroid = np.load('data/TreatedRoomSmallSet/Human1/centroid.npy')\n",
    "\n",
    "# Calculer les niveaux RMS pour chaque enregistrement pour les 4 micros\n",
    "rms_audio = np.sqrt(np.mean(np.square(audio), axis=2))\n",
    "\n",
    "# Concaténer les niveaux RMS avec les positions de centroid\n",
    "data_with_positions = np.concatenate((rms_audio, centroid), axis=1)\n",
    "\n",
    "# Sauvegarder les données combinées dans le dossier \"data\"\n",
    "np.save('data/donnees_combinees.npy', data_with_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 225.58790131150187\n",
      "Prédiction de la position pour les niveaux RMS : [[  30.39965014   32.66303892   19.03932157   27.20772662   26.55977958\n",
      "    38.11476921 1970.49231441 -980.28317514]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger les données combinées (niveaux RMS et positions) depuis le dossier \"data\"\n",
    "data_with_positions = np.load('data/donnees_combinees.npy')\n",
    "\n",
    "# Séparer les features (niveaux RMS) et les labels (positions)\n",
    "X = data_with_positions[:, :4]  # Les 4 premières colonnes sont les features (niveaux RMS)\n",
    "y = data_with_positions[:, 4:]  # Les colonnes suivantes sont les labels (positions)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer un modèle de régression linéaire\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les positions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculer l'erreur moyenne quadratique (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# Exemple de prédiction pour une nouvelle donnée (pour illustrer)\n",
    "nouvelle_donnee = np.array([[30.0, 28.0, 26.0, 24.0]])  # Nouveaux niveaux RMS à prédire\n",
    "prediction = model.predict(nouvelle_donnee)\n",
    "print(\"Prédiction de la position pour les niveaux RMS :\", prediction)\n",
    "\n",
    "# Sauvegarder le modèle entraîné si nécessaire\n",
    "# from joblib import dump\n",
    "# dump(model, 'modele_de_regression.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) après amélioration: [747.79629915]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Créer un pipeline avec PolynomialFeatures et Ridge Regression\n",
    "model = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False),\n",
    "    Ridge(alpha=0.1)\n",
    ")\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les positions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculer l'erreur moyenne quadratique (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) après amélioration:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PolynomialFeatures :\n",
    "Crée de nouvelles caractéristiques en combinant les niveaux RMS de manière à capturer des relations plus complexes entre les données.\n",
    "\n",
    "Ridge Regression :\n",
    "Permet de mieux gérer les relations complexes en ajoutant une régularisation qui évite le surajustement.\n",
    "Ce que le Code Fait :\n",
    "Il transforme les données d'entraînement en caractéristiques polynomiales.\n",
    "Entraîne un modèle de régression linéaire avec régularisation Ridge sur ces nouvelles caractéristiques.\n",
    "Prédit les positions à partir des niveaux RMS pour les données de test.\n",
    "Calcule l'erreur (RMSE) pour évaluer la performance du modèle.\n",
    "\n",
    "Résumé :\n",
    "Le code améliore la régression linéaire en lui permettant de mieux capturer les relations complexes entre les niveaux RMS et les positions grâce à l'ajout de caractéristiques polynomiales et à la régularisation Ridge. Cela devrait conduire à des prédictions plus précises et à un modèle moins sensible au surajustement.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (69.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.62.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Downloading keras-3.3.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/mamba/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Downloading optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/mamba/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/mamba/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/mamba/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/mamba/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.3.2-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (312 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.0/312.0 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, mdurl, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, markdown-it-py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.62.2 h5py-3.11.0 keras-3.3.2 libclang-18.1.1 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.11.0 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:44:01.709345: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-23 12:44:01.714506: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-23 12:44:01.770504: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-23 12:44:02.824532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Concatenate, Flatten\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = np.load('data/TreatedRoomSmallSet/Human1/audio.npy')\n",
    "centroid = np.load('data/TreatedRoomSmallSet/Human1/centroid.npy')\n",
    "skeletons = np.load('data/TreatedRoomSmallSet/Human1/skeletons.npy')\n",
    "rms_audio = np.sqrt(np.mean(np.square(audio), axis=2))\n",
    "\n",
    "# Normaliser les données audio (optionnel mais souvent utile)\n",
    "rms_audio = (rms_audio - np.mean(rms_audio, axis=0)) / np.std(rms_audio, axis=0)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_audio_train, X_audio_test, X_skeletons_train, X_skeletons_test, y_train, y_test = train_test_split(\n",
    "    rms_audio, skeletons, centroid, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de rms_audio: (3, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Charger les données audio et centroid\n",
    "audio = np.load('data/TreatedRoomSmallSet/Human1/audio.npy')\n",
    "centroid = np.load('data/TreatedRoomSmallSet/Human1/centroid.npy')\n",
    "\n",
    "# Calculer les niveaux RMS pour chaque enregistrement pour les 4 micros\n",
    "rms_audio = np.sqrt(np.mean(np.square(audio), axis=2))\n",
    "\n",
    "# Vérifier la forme de rms_audio\n",
    "print(\"Shape de rms_audio:\", rms_audio.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_audio (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_audio (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,410</span> (411.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m105,410\u001b[0m (411.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,410</span> (411.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,410\u001b[0m (411.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Reshape\n",
    "\n",
    "# Charger les données audio et centroid\n",
    "audio = np.load('data/TreatedRoomSmallSet/Human1/audio.npy')\n",
    "centroid = np.load('data/TreatedRoomSmallSet/Human1/centroid.npy')\n",
    "\n",
    "# Calculer les niveaux RMS pour chaque enregistrement pour les 4 micros\n",
    "rms_audio = np.sqrt(np.mean(np.square(audio), axis=2))\n",
    "\n",
    "# Entrée pour les niveaux RMS des micros\n",
    "input_audio = Input(shape=(rms_audio.shape[1],), name='input_audio')\n",
    "\n",
    "# Reshape pour ajouter une dimension (1D pour Conv1D)\n",
    "reshaped_audio = Reshape((rms_audio.shape[1], 1))(input_audio)\n",
    "\n",
    "# Couches Convolutionnelles pour l'audio\n",
    "conv1 = Conv1D(32, 3, activation='relu', padding='same')(reshaped_audio)\n",
    "maxpool1 = MaxPooling1D(2)(conv1)\n",
    "conv2 = Conv1D(64, 3, activation='relu', padding='same')(maxpool1)\n",
    "maxpool2 = MaxPooling1D(2)(conv2)\n",
    "\n",
    "# Couche LSTM pour la fusion temporelle\n",
    "lstm_fusion = LSTM(128, return_sequences=False)(maxpool2)\n",
    "\n",
    "# Couche Dense pour la prédiction de la localisation\n",
    "output = Dense(2, activation='linear', name='output')(lstm_fusion)\n",
    "\n",
    "# Créer le modèle\n",
    "model = Model(inputs=input_audio, outputs=output)\n",
    "\n",
    "# Compiler le modèle avec la fonction de perte appropriée\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Afficher un résumé du modèle\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3847904.7500 - val_loss: 3158178.7500\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 3847706.5000 - val_loss: 3158049.5000\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 3847507.0000 - val_loss: 3157915.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 3847300.0000 - val_loss: 3157770.7500\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3847079.5000 - val_loss: 3157613.2500\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 3846839.0000 - val_loss: 3157438.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 3846571.5000 - val_loss: 3157240.2500\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 3846271.5000 - val_loss: 3157014.2500\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 3845932.5000 - val_loss: 3156755.2500\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 3845546.0000 - val_loss: 3156458.0000\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    X_audio_train, y_train,\n",
    "    validation_data=(X_audio_test, y_test),\n",
    "    epochs=10, batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Fonction pour créer le modèle\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(4,)),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(2)  # 2 sorties pour les positions x et y\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Créer le modèle\n",
    "model = create_model()\n",
    "\n",
    "# Compiler le modèle avec un taux d'apprentissage réduit\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836ms/step - loss: 3813142.2500 - val_loss: 3146071.5000\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3811064.0000 - val_loss: 3144527.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3808991.0000 - val_loss: 3143011.2500\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 3806911.7500 - val_loss: 3141492.2500\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3804826.5000 - val_loss: 3139971.2500\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3802734.5000 - val_loss: 3138446.7500\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3800628.7500 - val_loss: 3136925.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3798568.5000 - val_loss: 3135407.5000\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3796500.7500 - val_loss: 3133894.5000\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 3794357.0000 - val_loss: 3132510.2500\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 3792206.0000 - val_loss: 3131107.5000\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 3790050.5000 - val_loss: 3129686.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3787877.5000 - val_loss: 3128259.5000\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 3785684.7500 - val_loss: 3126832.5000\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 3783455.0000 - val_loss: 3125406.2500\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3781355.7500 - val_loss: 3124027.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 3779426.2500 - val_loss: 3122850.5000\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 3777515.2500 - val_loss: 3121683.5000\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 3775608.2500 - val_loss: 3120519.7500\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 3773661.5000 - val_loss: 3119356.5000\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3771675.0000 - val_loss: 3118189.5000\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3769649.0000 - val_loss: 3117091.7500\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3767582.7500 - val_loss: 3116034.5000\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 3765475.7500 - val_loss: 3115000.7500\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3763337.2500 - val_loss: 3113971.7500\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 3761158.7500 - val_loss: 3112933.5000\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 3758936.0000 - val_loss: 3111883.7500\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 3756694.5000 - val_loss: 3110821.5000\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 3754411.5000 - val_loss: 3109745.2500\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 3752145.0000 - val_loss: 3108514.5000\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 3749777.0000 - val_loss: 3107207.5000\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 3747330.0000 - val_loss: 3105839.5000\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3744862.0000 - val_loss: 3104474.5000\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 3742361.5000 - val_loss: 3103107.7500\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 3739804.0000 - val_loss: 3101736.5000\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 3737190.0000 - val_loss: 3100358.5000\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 3734497.0000 - val_loss: 3098978.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 3731739.5000 - val_loss: 3097524.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 3728918.0000 - val_loss: 3095979.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3726045.5000 - val_loss: 3094415.2500\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3723140.0000 - val_loss: 3092831.2500\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 3720169.2500 - val_loss: 3091225.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 3717131.5000 - val_loss: 3089594.5000\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3714025.0000 - val_loss: 3087938.7500\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 3710874.5000 - val_loss: 3086170.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3707631.0000 - val_loss: 3084308.7500\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 3704308.2500 - val_loss: 3082430.2500\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 3700941.0000 - val_loss: 3080530.7500\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 3697510.5000 - val_loss: 3078609.2500\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 3694001.0000 - val_loss: 3076662.2500\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle avec plus d'époques et validation\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50, batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3861572.0000 - val_loss: 3167674.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3857250.0000 - val_loss: 3163801.2500\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 3852958.0000 - val_loss: 3160244.7500\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 3848841.7500 - val_loss: 3156787.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3844883.0000 - val_loss: 3153323.5000\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3840924.0000 - val_loss: 3149857.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3836968.2500 - val_loss: 3146385.7500\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 3833012.7500 - val_loss: 3142907.5000\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 3829479.5000 - val_loss: 3140233.2500\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 3827282.0000 - val_loss: 3138001.7500\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 3824999.0000 - val_loss: 3135713.5000\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 3822639.7500 - val_loss: 3133372.2500\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 3820211.0000 - val_loss: 3130981.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 3817733.2500 - val_loss: 3128539.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 3815204.0000 - val_loss: 3126096.7500\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 3812648.5000 - val_loss: 3123629.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 3810036.0000 - val_loss: 3121096.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 3807363.0000 - val_loss: 3118495.5000\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 3804549.7500 - val_loss: 3115826.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 3801563.5000 - val_loss: 3113151.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 3798497.5000 - val_loss: 3110365.7500\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 3795344.5000 - val_loss: 3107480.5000\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3792050.5000 - val_loss: 3104492.7500\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 3788621.5000 - val_loss: 3101442.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 3785025.5000 - val_loss: 3098386.2500\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 3781478.0000 - val_loss: 3095133.5000\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 3777770.7500 - val_loss: 3091740.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 3773823.2500 - val_loss: 3088194.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 3769672.2500 - val_loss: 3084486.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 3765399.5000 - val_loss: 3080661.5000\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 3760955.5000 - val_loss: 3076777.2500\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 3756415.0000 - val_loss: 3072700.7500\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 3751648.0000 - val_loss: 3068426.7500\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 3746661.0000 - val_loss: 3063951.5000\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 3741434.2500 - val_loss: 3059263.7500\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 3735969.0000 - val_loss: 3054363.2500\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3730254.7500 - val_loss: 3049261.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 3724274.2500 - val_loss: 3043922.2500\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 3718015.2500 - val_loss: 3038339.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 3711469.5000 - val_loss: 3032502.2500\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 3704622.5000 - val_loss: 3026403.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 3697481.5000 - val_loss: 3020031.2500\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 3690018.5000 - val_loss: 3013378.2500\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 3682217.5000 - val_loss: 3006431.2500\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3674065.0000 - val_loss: 2999181.2500\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 3665548.2500 - val_loss: 2991615.5000\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 3656653.2500 - val_loss: 2983723.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 3647369.0000 - val_loss: 2975772.2500\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 3637790.0000 - val_loss: 2967464.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 3627956.0000 - val_loss: 2958772.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Créer un modèle de réseau de neurones profond\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(4,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(2)  # 2 sorties pour les positions x et y\n",
    "])\n",
    "\n",
    "# Compiler le modèle avec un taux d'apprentissage réduit\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Entraîner le modèle avec plus d'époques et validation\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50, batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 2958772.0000\n",
      "Loss sur les données de test : 2958772.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "Prédiction de la position pour les niveaux RMS : [[ 71.65536 -43.78367]]\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle sur les données de test\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(\"Loss sur les données de test :\", test_loss)\n",
    "\n",
    "# Prédiction sur une nouvelle donnée\n",
    "nouvelle_donnee = np.array([[30.0, 28.0, 26.0, 24.0]])  # Nouveaux niveaux RMS à prédire\n",
    "prediction = model.predict(nouvelle_donnee)\n",
    "print(\"Prédiction de la position pour les niveaux RMS :\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le \"Loss sur les données de test\" est de 2958772.0. Cela représente la moyenne des erreurs au carré entre les positions réelles et les positions prédites sur les données de test. Plus le Loss est bas, mieux le modèle performe. Cela montre que le modèle a atteint un Loss de 2958772.0 sur les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Root Mean Squared Error (RMSE) sur les données de test: 1720.1081372516912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculer les prédictions sur les données de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) sur les données de test:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Afficher la courbe de perte pendant l'entraînement\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le modèle\n",
    "model.save('model_crnn_acoustic.h5')\n",
    "\n",
    "# Pour charger le modèle plus tard\n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model('model_crnn_acoustic.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
